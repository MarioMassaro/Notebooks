{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Sordo_Mudo.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xvPZcm4QM6N"
      },
      "source": [
        "# importamos librerias\n",
        "\n",
        "# tratado de datos\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# visualizacion \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "# deep learning\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "\n",
        "# funciones necesarias\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "from skimage.io import imread"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQxWUSwSQM6V"
      },
      "source": [
        "#Cargamos nuestro data set\n",
        "IMAGE_SIZE = 100\n",
        "TRAIN_PATH = \"path al data.train\"\n",
        "TEST_PATH = \"path al data.test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjBwE_DQQM6W"
      },
      "source": [
        "# df_test \n",
        "\n",
        "def read_data(path):\n",
        "    archivos = []\n",
        "    for file in os.listdir(path): \n",
        "            archivos.append(file)            \n",
        "    return np.array(archivos)\n",
        "    \n",
        "archivos_test = read_data(TEST_PATH)\n",
        "\n",
        "df_test = pd.DataFrame({\n",
        "    'archivo': archivos_test})\n",
        "\n",
        "\n",
        "# df_train\n",
        "\n",
        "df_train = pd.read_csv(\"path al data.target\")\n",
        "\n",
        "# One Hot Encoder \n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df_train[\"target\"] = df_train[\"target\"].astype('category')\n",
        "df_train[\"target_2\"] = df_train[\"target\"].cat.codes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYmw4SLsQM6b",
        "outputId": "05e70545-4d1a-4aee-d85e-d0c5b1f621ec"
      },
      "source": [
        "# Revisamos la si limpieza fue completada con exito\n",
        "df_train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9000 entries, 0 to 8999\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype   \n",
            "---  ------    --------------  -----   \n",
            " 0   archivo   9000 non-null   object  \n",
            " 1   target    9000 non-null   category\n",
            " 2   target_2  9000 non-null   int8    \n",
            "dtypes: category(1), int8(1), object(1)\n",
            "memory usage: 89.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtLFbc25QM6c"
      },
      "source": [
        "# Train\n",
        "def read_data(df, path, image_size):\n",
        "    X = []\n",
        "    Y = []\n",
        "    \n",
        "    for index, row in df.iterrows():\n",
        "        image = imread(os.path.join(path, row['archivo']))\n",
        "        \n",
        "        smallimage = cv2.resize(image, (IMAGE_SIZE,IMAGE_SIZE))\n",
        "        X.append(smallimage)\n",
        "        \n",
        "        Y.append(row['target'])\n",
        "\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "X_train, y_train = read_data(df_train, TRAIN_PATH, IMAGE_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V49HeLbNQM6f"
      },
      "source": [
        "# Test\n",
        "def read_data2(df, path, image_size):\n",
        "    X = []\n",
        "    Y = []\n",
        "    \n",
        "    for index, row in df.iterrows():\n",
        "        image = imread(os.path.join(path, row['archivo']))\n",
        "        \n",
        "        smallimage = cv2.resize(image, (IMAGE_SIZE,IMAGE_SIZE))\n",
        "        X.append(smallimage)\n",
        "\n",
        "    return np.array(X)\n",
        "\n",
        "X_test = read_data2(df_test, TEST_PATH, IMAGE_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM8GESTgQM6g"
      },
      "source": [
        "# Escalamos nuestras imagenes\n",
        "X_train_norma = X_train / 255.0\n",
        "X_test_norma = X_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SE-mlGSQM6h"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# aumentamos nuestra cantidad de datos con fotos generadas a partir de las que ya tenemos\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,                                   \n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# reescalamos el validation ya que no debe estar escalado\n",
        "validation_datagen = ImageDataGenerator(rescale = 1.0/255. )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KNMwNDaQM6i",
        "outputId": "56f76741-1ca1-49e3-9d5f-34742d58e946"
      },
      "source": [
        "# preparamos el entrenamiento\n",
        "train_generator = train_datagen.flow_from_dataframe(df_train,\n",
        "                                                    TRAIN_PATH,\n",
        "                                                    x_col='archivo',\n",
        "                                                    y_col='target',\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'sparse',\n",
        "                                                    target_size = (IMAGE_SIZE, IMAGE_SIZE))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9000 validated image filenames belonging to 29 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"# Flow validation images in batches of 20 using test_datagen generator\\nvalidation_generator = validation_datagen.flow_from_dataframe(validate_df,\\n                                                              TRAIN_PATH,\\n                                                              x_col='archivo',\\n                                                              y_col='target_2',\\n                                                              batch_size = 20,\\n                                                              class_mode = 'sparse',\\n                                                              target_size = (IM_SIZE, IM_SIZE))\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur6-1Oi5QM6j"
      },
      "source": [
        "# Creamos nuestra red neuronal para el modelo utilizando un modelo Pre-entrenado como el VGG16\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "base_model = VGG16(input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3),\n",
        "                  include_top=False)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "    \n",
        "# Capa de entrada\n",
        "x = keras.layers.Flatten()(base_model.output)\n",
        "\n",
        "# Capa de procesado\n",
        "x = keras.layers.Dense(1000, activation='relu')(x)\n",
        "x = keras.layers.Dense(1000, activation='sigmoid')(x)\n",
        "x = keras.layers.Dropout(0.5)(x)\n",
        "x = keras.layers.Dense(1000, activation='sigmoid')(x)\n",
        "x = keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "# Capa de salida con 29 resultados ya que habian 29 letras en las imagenes anteriores\n",
        "x = keras.layers.Dense(29, activation='softmax')(x)\n",
        "\n",
        "# Terminamos el modelo usando el sparse_categorical_crossentropy\n",
        "model = tf.keras.models.Model(base_model.input, x)\n",
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',metrics = ['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmcdXj3oQM6j"
      },
      "source": [
        "# Corremos el modelo y vemos que tal la precision\n",
        "vgghist = model.fit(train_generator,\n",
        "                    epochs = 35,\n",
        "                    batch_size=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2RzznsWQM6l",
        "outputId": "e87ecfe4-7a64-4660-87e3-2201224bceff"
      },
      "source": [
        "# Vemos las predicciones\n",
        "predictions = model.predict(X_test_norma)\n",
        "predict = predictions.argmax(axis=1)\n",
        "predict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1, 21, 23, ..., 21,  3,  0], dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnCuO2-fQM6p"
      },
      "source": [
        "df_test['target']=predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85OtTddiQM6p",
        "outputId": "96993168-ffea-4253-dfe4-06c1c2572a21"
      },
      "source": [
        "# Aqui podemos ver el resultado de las predicciones\n",
        "series = {}\n",
        "\n",
        "for i in range(0,29):\n",
        "    A = df_train[df_train['target_2']==i]['target'].head(1)\n",
        "    B =A.values\n",
        "    \n",
        "    series[B[0]]=i\n",
        "    \n",
        "print(series)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25, 'del': 26, 'nothing': 27, 'space': 28}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}